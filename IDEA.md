Поговорив с Василием мы пришли к следующей архитектуре. Для работы моего сервиса существую следующие игроки backend Василия ( Далее emonomy backend), мой streamlit manager API, и индивидуальные контейнеры с запущенными streamlit app (далее streamlit app). Когда на emonomy backend обращается клиент с просьбой открыть результат, посылается GET запрос в  streamlit manager API со списком работающих клиентов. Если таковых нет (в начале их нет), то backend генерирует данные в нужном формате и посылает POST запрос прикрепляя данные к нему, на генерацию нового контейнера (вопрос с тем нужна ли какая-то заглушка пока грузиться страница нужно подумать). Контейнер поднимается, и его порт передается в ингресс (nginx или backend) и тот форвардит streamlit нашему клиенту. Далее они работают в нем.
Если происходит обращение на URL клиента и оказывается что такой контейнер уже поднят, то просто делается переадресация на него (задержки почти нет). У нас таким образом поддерживается кэш из N работающих контейнеров по 100-200 MB каждый. Если контейнеров становиться больше  N, то самый старый останавливается и нужен повторный POST запрос при необходимости его поднять. О том какие подняты узнаем опять же из GET  запроса.

Плюсы: Можно держать несколько видов данных и несколько видов экспериментов. Можно форсом перегенирировать контейнер если хочется что-то поменять в его шаблоне.